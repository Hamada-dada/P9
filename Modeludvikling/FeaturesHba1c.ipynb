{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "SAMMEDAG_4M2M_PATH = Path(r\"C:\\Users\\kfq6\\Documents\\Data\\Sammedag_master_means_4m2m_3to4.xlsx\")\n",
    "LABKA_PATH         = Path(r\"C:\\Users\\kfq6\\Documents\\Data\\LABKA_wide_numeric.xlsx\")\n",
    "\n",
    "OUT_PATH = Path(r\"C:\\Users\\kfq6\\Documents\\Data\\Sammedag_master_HbA1c_Features.xlsx\")\n",
    "\n",
    "ID_COL = \"DW_EK_Borger\"\n",
    "\n",
    "# Lab columns in Sammedag master\n",
    "HBA1C_COL = \"LABmean__hb_b_haemoglobin_a1c_ifcc_mmol_mol\"\n",
    "LDL_COL   = \"LABmean__p_kolesterol_ldl_mmol_l\"\n",
    "EGFR_COL  = \"LABmean__egfr_1_73m2_ckd_epi_ml_min\"\n",
    "\n",
    "# HbA1c in LABKA\n",
    "HBA1C_LABKA_COL = \"Hb(B)-Hæmoglobin_A1c_(IFCC)_[mmol_mol]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- HELPERS ----------------\n",
    "def missing_table(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    missing_count = df_in.isna().sum()\n",
    "    missing_percent = (missing_count / len(df_in)) * 100\n",
    "    tbl = pd.DataFrame({\n",
    "        \"Missing Count\": missing_count,\n",
    "        \"Missing %\": missing_percent.round(2),\n",
    "    })\n",
    "    tbl = tbl[tbl[\"Missing Count\"] > 0].sort_values(\"Missing %\", ascending=False)\n",
    "    return tbl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 27 meta columns.\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------- LOAD SAMMEDAG & BASIC CLEANING ----------------\n",
    "df = pd.read_excel(SAMMEDAG_4M2M_PATH, sheet_name=\"Sheet1\")\n",
    "\n",
    "df[\"anchor_date\"] = pd.to_datetime(df[\"anchor_date\"], errors=\"coerce\")\n",
    "df[\"year\"] = df[\"anchor_date\"].dt.year\n",
    "\n",
    "print(\"=== RAW 4m2m_3to4 AT LOAD ===\")\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Unique patients:\", df[ID_COL].nunique())\n",
    "\n",
    "anchor_counts_raw = df.groupby(ID_COL).size()\n",
    "print(\"\\nRows per patient (raw):\")\n",
    "print(anchor_counts_raw.value_counts().sort_index())\n",
    "\n",
    "\n",
    "# Drop meta columns that you truly don't want for modelling\n",
    "drop_meta = [\n",
    "    \"window_type\", \"has_who_in_window\",\n",
    "    \"window_start\", \"window_end\",\n",
    "    \"anchor_first_time\", \"anchor_last_time\",\n",
    "    \"visit_datetimes\", \"visit_topics\", \"visit_statuses\",\n",
    "    \"lab_window_start\", \"lab_window_end\", \"diabetes_type\",\n",
    "    \"who_date\",\n",
    "    \"LABmean__u_albumin_kreatinin_ratio_x_10_3\",\n",
    "    \"LABmean__p_albumin_g_l\", \"comp_ketoac\", \"comp_coma\",\n",
    "    \"LABmean__p_25_hydroxy_vitamin_d_d3_d2_nmol_l\",\n",
    "    \"n_anchor_bookings_that_day\",\n",
    "    \"LABmean__p_calcium_albuminkorrigeret_mmol_l\",\n",
    "    \"LABmean__p_calcium_mmol_l\",\n",
    "    \"who_days_from_anchor\",\n",
    "    \"n_visits_in_window\",\n",
    "    \"comp_any\",\n",
    "    \"has_lab_in_window\",\n",
    "    \"lab_window_n_rows\",\n",
    "    \"n_anchors\",\n",
    "]\n",
    "drop_meta_existing = [c for c in drop_meta if c in df.columns]\n",
    "df = df.drop(columns=drop_meta_existing)\n",
    "print(f\"\\nDropped {len(drop_meta_existing)} meta columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missingness overview (top 20):\n",
      "                                             Missing Count  Missing %\n",
      "who_score                                              710      25.67\n",
      "LABmean__u_albumin_kreatinin_ratio_mg_g                542      19.60\n",
      "LABmean__b_haemoglobin_mmol_l                          497      17.97\n",
      "LABmean__p_kolesterol_ldl_mmol_l                       117       4.23\n",
      "LABmean__p_vitamin_b12_pmol_l                           83       3.00\n",
      "LABmean__p_kolesterol_hdl_mmol_l                        74       2.68\n",
      "LABmean__p_kolesterol_mmol_l                            73       2.64\n",
      "LABmean__p_triglycerid_mmol_l                           73       2.64\n",
      "LABmean__p_kalium_mmol_l                                63       2.28\n",
      "LABmean__p_natrium_mmol_l                               61       2.21\n",
      "LABmean__egfr_1_73m2_ckd_epi_ml_min                     56       2.02\n",
      "LABmean__p_kreatinin_umol_l                             56       2.02\n",
      "LABmean__hb_b_haemoglobin_a1c_ifcc_mmol_mol             53       1.92\n",
      "\n",
      "Saved feature-augmented dataset to: C:\\Users\\kfq6\\Documents\\Data\\Sammedag_master_HbA1c_Features.xlsx\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------- AUDIT MISSINGNESS IN REQUIRED LABS ----------------\n",
    "target_cols = [HBA1C_COL, LDL_COL, EGFR_COL]\n",
    "\n",
    "print(\"\\n=== MISSINGNESS AUDIT (before any dropping) ===\")\n",
    "row_missing_any = df[target_cols].isna().any(axis=1)\n",
    "\n",
    "n_rows_missing = row_missing_any.sum()\n",
    "rows_with_missing = df[row_missing_any]\n",
    "bad_ids = rows_with_missing[ID_COL].unique()\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Rows with missing in any of {target_cols}: {n_rows_missing}\")\n",
    "print(f\"Patients with >=1 row missing any required lab: {len(bad_ids)}\")\n",
    "\n",
    "# How many missing rows per patient?\n",
    "miss_counts = rows_with_missing.groupby(ID_COL).size()\n",
    "print(\"\\nMissing rows per patient (only patients with at least one missing):\")\n",
    "print(miss_counts.value_counts().sort_index())\n",
    "\n",
    "print(\"\\nRows per patient BEFORE dropping any rows:\")\n",
    "print(df.groupby(ID_COL).size().value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with at least one missing required HbA1c: 101\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------- DROP ONLY INCOMPLETE ROWS ----------------\n",
    "df[\"missing_any_of_three\"] = row_missing_any\n",
    "\n",
    "df_complete = df[~df[\"missing_any_of_three\"]].copy()\n",
    "df_complete = df_complete.drop(columns=[\"missing_any_of_three\"])\n",
    "\n",
    "print(\"\\n=== AFTER DROPPING INCOMPLETE YEARS (ROW-WISE) ===\")\n",
    "print(\"Rows:\", len(df_complete))\n",
    "print(\"Patients:\", df_complete[ID_COL].nunique())\n",
    "\n",
    "anchor_counts_complete = df_complete.groupby(ID_COL).size()\n",
    "print(\"\\nRows per patient (after dropping incomplete years):\")\n",
    "print(anchor_counts_complete.value_counts().sort_index())\n",
    "\n",
    "# How many patients lost ALL rows?\n",
    "ids_after = set(df_complete[ID_COL].unique())\n",
    "ids_before = set(df[ID_COL].unique())\n",
    "lost_all = ids_before - ids_after\n",
    "print(f\"\\nPatients who lost ALL rows after row-wise drop: {len(lost_all)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows per patient distribution in features df:\n",
      "3    862\n",
      "4     45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------- OPTIONAL: ENFORCE MINIMUM YEARS ----------------\n",
    "min_years = 3   # ≥3 complete lab-years\n",
    "\n",
    "counts_after = df_complete.groupby(ID_COL).size()\n",
    "good_ids = counts_after[counts_after >= min_years].index\n",
    "\n",
    "print(f\"\\nPatients with ≥{min_years} COMPLETE years:\", len(good_ids))\n",
    "\n",
    "df_final = df_complete[df_complete[ID_COL].isin(good_ids)].copy()\n",
    "\n",
    "print(\"=== FINAL COHORT FOR FEATURES (after min_years filter) ===\")\n",
    "print(\"Final rows:\", len(df_final))\n",
    "print(\"Final patients:\", df_final[ID_COL].nunique())\n",
    "print(\"\\nRows per patient in FINAL df:\")\n",
    "print(df_final.groupby(ID_COL).size().value_counts().sort_index())\n",
    "\n",
    "# Sanity: show a few example patients and their years\n",
    "print(\"\\nExample patients and their years in final df:\")\n",
    "example_ids = df_final[ID_COL].drop_duplicates().sample(\n",
    "    min(5, len(df_final[ID_COL].unique())),\n",
    "    random_state=42\n",
    ")\n",
    "for pid in example_ids:\n",
    "    sub = df_final[df_final[ID_COL] == pid][[ID_COL, \"year\"]].sort_values(\"year\")\n",
    "    print(sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2766\n",
      "Rows with missing in any target: 119\n",
      "Rows after dropping incomplete years: 2647\n",
      "Patients remaining after row-wise drop: 904\n",
      "Patients with ≥4 complete years: 42\n",
      "Final rows: 168\n",
      "Final patients: 42\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------- HBA1C SLOPE / CV / MAC OVER LAST YEAR ----------------\n",
    "df_labka_ts = pd.read_excel(LABKA_PATH)\n",
    "df_labka_ts[\"Testdato\"] = pd.to_datetime(df_labka_ts[\"Testdato\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# Only keep LABKA rows for patients that survived all filtering\n",
    "df_labka_ts = df_labka_ts[df_labka_ts[ID_COL].isin(df_final[ID_COL].unique())].copy()\n",
    "\n",
    "df_labka_ts = df_labka_ts[[ID_COL, \"Testdato\", HBA1C_LABKA_COL]].copy()\n",
    "df_labka_ts[HBA1C_LABKA_COL] = pd.to_numeric(df_labka_ts[HBA1C_LABKA_COL], errors=\"coerce\")\n",
    "df_labka_ts = df_labka_ts.dropna(subset=[HBA1C_LABKA_COL, \"Testdato\"])\n",
    "\n",
    "slope_results = []\n",
    "cv_results = []\n",
    "mac_results = []\n",
    "\n",
    "for _, row in df_final.iterrows():\n",
    "    pid = row[ID_COL]\n",
    "    anchor_date = row[\"anchor_date\"]\n",
    "\n",
    "    if pd.isna(anchor_date):\n",
    "        slope_results.append(np.nan)\n",
    "        cv_results.append(np.nan)\n",
    "        mac_results.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    start_date = anchor_date - pd.DateOffset(years=1)\n",
    "    end_date = anchor_date\n",
    "\n",
    "    df_patient = df_labka_ts[\n",
    "        (df_labka_ts[ID_COL] == pid) &\n",
    "        (df_labka_ts[\"Testdato\"] >= start_date) &\n",
    "        (df_labka_ts[\"Testdato\"] < end_date)\n",
    "    ].copy()\n",
    "\n",
    "    if len(df_patient) < 2:\n",
    "        slope_results.append(np.nan)\n",
    "        cv_results.append(np.nan)\n",
    "        mac_results.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    df_patient = df_patient.sort_values(\"Testdato\")\n",
    "    X = (df_patient[\"Testdato\"] - df_patient[\"Testdato\"].min()).dt.days.values.reshape(-1, 1)\n",
    "    y = df_patient[HBA1C_LABKA_COL].values\n",
    "\n",
    "    # Slope\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    slope = model.coef_[0]\n",
    "    slope_results.append(slope)\n",
    "\n",
    "    # CV\n",
    "    mean = y.mean()\n",
    "    if mean == 0 or np.isnan(mean):\n",
    "        cv_results.append(np.nan)\n",
    "    else:\n",
    "        std = y.std(ddof=1)\n",
    "        cv = std / mean\n",
    "        cv_results.append(cv)\n",
    "\n",
    "    # MAC\n",
    "    if len(y) < 2:\n",
    "        mac_results.append(np.nan)\n",
    "    else:\n",
    "        mac = np.mean(np.abs(np.diff(y)))\n",
    "        mac_results.append(mac)\n",
    "\n",
    "df_final[\"HbA1c_slope_prev_year\"] = slope_results\n",
    "df_final[\"HbA1c_CV_prev_year\"] = cv_results\n",
    "df_final[\"HbA1c_MAC_prev_year\"] = mac_results\n",
    "\n",
    "total = len(df_final)\n",
    "n_slope_nan = df_final[\"HbA1c_slope_prev_year\"].isna().sum()\n",
    "n_cv_nan    = df_final[\"HbA1c_CV_prev_year\"].isna().sum()\n",
    "n_mac_nan   = df_final[\"HbA1c_MAC_prev_year\"].isna().sum()\n",
    "\n",
    "print(f\"\\nMissing HbA1c slope values: {n_slope_nan} / {total} ({n_slope_nan / total * 100:.2f}%)\")\n",
    "print(f\"Missing HbA1c CV values:    {n_cv_nan} / {total} ({n_cv_nan / total * 100:.2f}%)\")\n",
    "print(f\"Missing HbA1c MAC values:   {n_mac_nan} / {total} ({n_mac_nan / total * 100:.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missingness overview (top 20):\n",
      "                                         Missing Count  Missing %\n",
      "LABmean__u_albumin_kreatinin_ratio_mg_g             39      30.95\n",
      "who_score                                           37      29.37\n",
      "LABmean__b_haemoglobin_mmol_l                       27      21.43\n",
      "LABmean__p_vitamin_b12_pmol_l                        1       0.79\n",
      "\n",
      "Saved feature-augmented dataset to: C:\\Users\\kfq6\\Documents\\Data\\Sammedag_master_HbA1c_Features.xlsx\n"
     ]
    }
   ],
   "source": [
    "# %% ---------------- BUILD NEXT-YEAR HBA1C TARGET ----------------\n",
    "# Sort to guarantee temporal order within each patient\n",
    "df_final = df_final.sort_values([ID_COL, \"anchor_date\"]).reset_index(drop=True)\n",
    "\n",
    "# Target: HbA1c at next annual screening for the same patient\n",
    "df_final[\"HbA1c_next\"] = (\n",
    "    df_final\n",
    "    .groupby(ID_COL)[HBA1C_COL]\n",
    "    .shift(-1)  # move next value up\n",
    ")\n",
    "\n",
    "# Also store timing of the next screening\n",
    "df_final[\"year_next\"] = df_final.groupby(ID_COL)[\"year\"].shift(-1)\n",
    "df_final[\"anchor_date_next\"] = df_final.groupby(ID_COL)[\"anchor_date\"].shift(-1)\n",
    "\n",
    "# Time gap in years to next screening (for sanity / later filtering if needed)\n",
    "df_final[\"delta_years_to_next\"] = (\n",
    "    (df_final[\"anchor_date_next\"] - df_final[\"anchor_date\"]).dt.days / 365.25\n",
    ")\n",
    "\n",
    "# Optional: previous HbA1c as a history feature\n",
    "df_final[\"HbA1c_prev\"] = (\n",
    "    df_final\n",
    "    .groupby(ID_COL)[HBA1C_COL]\n",
    "    .shift(1)\n",
    ")\n",
    "\n",
    "print(\"\\n=== TARGET CONSTRUCTION AUDIT ===\")\n",
    "print(\"Rows with non-missing HbA1c_next:\", df_final[\"HbA1c_next\"].notna().sum())\n",
    "print(\"Rows with missing HbA1c_next (expected: last per patient):\", df_final[\"HbA1c_next\"].isna().sum())\n",
    "\n",
    "pairs_per_patient = (\n",
    "    df_final.dropna(subset=[\"HbA1c_next\"])\n",
    "            .groupby(ID_COL)\n",
    "            .size()\n",
    ")\n",
    "print(\"Prediction pairs per patient (distribution):\")\n",
    "print(pairs_per_patient.value_counts().sort_index())\n",
    "\n",
    "# Quick sanity print of first few rows\n",
    "print(\"\\nPreview of year, HbA1c_current, HbA1c_next for first 10 rows:\")\n",
    "print(\n",
    "    df_final[[\"DW_EK_Borger\", \"year\", \"anchor_date\",\n",
    "              HBA1C_COL, \"year_next\", \"anchor_date_next\", \"HbA1c_next\"]]\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[478]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# %% ---------------- HBA1C SLOPE / CV / MAC OVER LAST YEAR ----------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_labka_ts = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLABKA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df_labka_ts[\u001b[33m\"\u001b[39m\u001b[33mTestdato\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(df_labka_ts[\u001b[33m\"\u001b[39m\u001b[33mTestdato\u001b[39m\u001b[33m\"\u001b[39m], dayfirst=\u001b[38;5;28;01mTrue\u001b[39;00m, errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m df_labka_ts = df_labka_ts[df_labka_ts[ID_COL].isin(df[ID_COL].unique())].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:517\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    512\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m     )\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     data = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    543\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1629\u001b[39m, in \u001b[36mExcelFile.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m   1589\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\n\u001b[32m   1590\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1591\u001b[39m     sheet_name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1609\u001b[39m     **kwds,\n\u001b[32m   1610\u001b[39m ) -> DataFrame | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[32m   1611\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1612\u001b[39m \u001b[33;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[32m   1613\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1627\u001b[39m \u001b[33;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   1628\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:793\u001b[39m, in \u001b[36mBaseExcelReader.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m    790\u001b[39m     sheet = \u001b[38;5;28mself\u001b[39m.get_sheet_by_index(asheetname)\n\u001b[32m    792\u001b[39m file_rows_needed = \u001b[38;5;28mself\u001b[39m._calc_rows(header, index_col, skiprows, nrows)\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_sheet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_rows_needed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    795\u001b[39m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[32m    796\u001b[39m     sheet.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:616\u001b[39m, in \u001b[36mOpenpyxlReader.get_sheet_data\u001b[39m\u001b[34m(self, sheet, file_rows_needed)\u001b[39m\n\u001b[32m    614\u001b[39m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] = []\n\u001b[32m    615\u001b[39m last_row_with_data = -\u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# trim trailing empty elements\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:81\u001b[39m, in \u001b[36mReadOnlyWorksheet._cells_by_row\u001b[39m\u001b[34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[39m\n\u001b[32m     77\u001b[39m src = \u001b[38;5;28mself\u001b[39m._get_source()\n\u001b[32m     78\u001b[39m parser = WorkSheetParser(src, \u001b[38;5;28mself\u001b[39m._shared_strings,\n\u001b[32m     79\u001b[39m                          data_only=\u001b[38;5;28mself\u001b[39m.parent.data_only, epoch=\u001b[38;5;28mself\u001b[39m.parent.epoch,\n\u001b[32m     80\u001b[39m                          date_formats=\u001b[38;5;28mself\u001b[39m.parent._date_formats)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[39m, in \u001b[36mWorkSheetParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    137\u001b[39m properties = {\n\u001b[32m    138\u001b[39m     PRINT_TAG: (\u001b[33m'\u001b[39m\u001b[33mprint_options\u001b[39m\u001b[33m'\u001b[39m, PrintOptions),\n\u001b[32m    139\u001b[39m     MARGINS_TAG: (\u001b[33m'\u001b[39m\u001b[33mpage_margins\u001b[39m\u001b[33m'\u001b[39m, PageMargins),\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m \n\u001b[32m    152\u001b[39m }\n\u001b[32m    154\u001b[39m it = iterparse(\u001b[38;5;28mself\u001b[39m.source) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtag\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\xml\\etree\\ElementTree.py:1251\u001b[39m, in \u001b[36miterparse.<locals>.iterator\u001b[39m\u001b[34m(source)\u001b[39m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m pullparser.read_events()\n\u001b[32m   1250\u001b[39m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m data = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\zipfile.py:951\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m    953\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Python311\\Lib\\zipfile.py:1027\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compress_type == ZIP_DEFLATED:\n\u001b[32m   1026\u001b[39m     n = \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m.MIN_READ_SIZE)\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m     \u001b[38;5;28mself\u001b[39m._eof = (\u001b[38;5;28mself\u001b[39m._decompressor.eof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1029\u001b[39m                  \u001b[38;5;28mself\u001b[39m._compress_left <= \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   1030\u001b[39m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail)\n\u001b[32m   1031\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# %% ---------------- MISSINGNESS TABLE & EXPORT ----------------\n",
    "missing_tbl = missing_table(df_final)\n",
    "print(\"\\nMissingness overview (top 20):\")\n",
    "print(missing_tbl.head(20))\n",
    "\n",
    "df_final.to_excel(OUT_PATH, index=False)\n",
    "print(f\"\\nSaved feature-augmented dataset to: {OUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
